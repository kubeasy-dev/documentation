---
title: Testing Challenges
description: How to test challenges locally before submission.
---

Thorough testing ensures your challenge works correctly and provides a good learning experience. This guide covers strategies for testing challenges at every stage.

## Testing workflow

Follow this workflow when testing a challenge:

1. **Setup** - Create a clean test environment
2. **Deploy** - Apply the broken manifests
3. **Verify problem** - Confirm the issue is reproducible
4. **Apply fix** - Solve the challenge
5. **Verify validations pass** - Submit and check results
6. **Clean up** - Reset for next test

## Setting up a test environment

### Using Kubeasy CLI (recommended)

The easiest way is to use the Kubeasy CLI which sets up everything automatically:

```bash
# Setup creates the cluster and installs all components
kubeasy setup
```

This command will:
- Create a Kind cluster named `kubeasy`
- Install ArgoCD for challenge deployment
- Install Kyverno for policy enforcement
- Configure kubectl context

**Benefits**:
- One command setup
- All components properly configured
- Same environment as production

### Manual setup (alternative)

If you prefer to set up components manually:

```bash
# Create a Kind cluster
kind create cluster --name kubeasy-test

# Install Kyverno
kubectl create -f https://github.com/kyverno/kyverno/releases/download/v1.11.0/install.yaml

# Wait for Kyverno to be ready
kubectl wait --for=condition=ready pod \
  -l app.kubernetes.io/name=kyverno \
  -n kyverno \
  --timeout=300s
```

## Testing the broken state

### 1. Start the challenge

```bash
kubeasy challenge start <challenge-slug>
```

Or if testing locally before the challenge is registered:

```bash
# Create namespace manually
kubectl create namespace challenge-<slug>

# Apply manifests
kubectl apply -f manifests/ -n challenge-<slug>

# Apply policies
kubectl apply -f policies/
```

### 2. Verify resources are created

```bash
# Check namespace
kubectl get ns challenge-<slug>

# Check resources in the namespace
kubectl get all -n challenge-<slug>
```

### 3. Confirm the problem exists

Depending on the challenge type:

**For pod failures:**
```bash
kubectl get pods -n challenge-<slug>
kubectl describe pod <pod-name> -n challenge-<slug>
kubectl logs <pod-name> -n challenge-<slug>
```

Expected: Pod should show errors (CrashLoopBackOff, OOMKilled, etc.)

**For RBAC issues:**
```bash
kubectl logs <pod-name> -n challenge-<slug>
```

Expected: Logs should show permission denied errors.

**For networking issues:**
```bash
kubectl exec -it <pod-name> -n challenge-<slug> -- curl http://service:port
```

Expected: Connection should fail.

## Testing the solution

### 1. Apply the fix

Manually apply the changes that solve the challenge:

```bash
# Example: Increase memory limit
kubectl patch deployment data-processor -n challenge-<slug> \
  --type='json' -p='[
    {"op": "replace", "path": "/spec/template/spec/containers/0/resources/limits/memory", "value": "256Mi"}
  ]'
```

### 2. Wait for resources to stabilize

```bash
# Wait for pod to be ready
kubectl wait --for=condition=ready pod \
  -l app=<app-label> \
  -n challenge-<slug> \
  --timeout=120s
```

### 3. Submit and verify validations

```bash
kubeasy challenge submit <challenge-slug>
```

All validations should pass. If any fail, the CLI will show which ones and why.

### 4. Manual validation checks

You can also manually verify each validation type:

**For condition validations:**
```bash
kubectl get pod <pod-name> -n challenge-<slug> -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}'
# Expected: True
```

**For status validations:**
```bash
kubectl get pod <pod-name> -n challenge-<slug> -o jsonpath='{.status.containerStatuses[0].restartCount}'
# Expected: Less than threshold
```

**For log validations:**
```bash
kubectl logs <pod-name> -n challenge-<slug> | grep "expected string"
# Expected: String should be found
```

**For event validations:**
```bash
kubectl get events -n challenge-<slug> --field-selector reason=OOMKilled
# Expected: No events (empty output)
```

**For connectivity validations:**
```bash
kubectl exec -it <source-pod> -n challenge-<slug> -- curl http://service:port/path
# Expected: HTTP 200
```

## Automated testing script

Create a test script for consistent testing:

```bash
#!/bin/bash
# test-challenge.sh

set -e

SLUG="memory-pressure"
NS="challenge-$SLUG"

echo "Cleaning up any previous test..."
kubeasy challenge clean $SLUG 2>/dev/null || true

echo "Starting challenge..."
kubeasy challenge start $SLUG

echo "Waiting for resources..."
sleep 10

echo "Checking broken state..."
kubectl get pods -n $NS
# Should show CrashLoopBackOff or similar

echo "Applying fix..."
kubectl patch deployment data-processor -n $NS \
  --type='json' -p='[
    {"op": "replace", "path": "/spec/template/spec/containers/0/resources/limits/memory", "value": "256Mi"},
    {"op": "replace", "path": "/spec/template/spec/containers/0/resources/requests/memory", "value": "128Mi"}
  ]'

echo "Waiting for pod to stabilize..."
sleep 30

echo "Submitting solution..."
kubeasy challenge submit $SLUG

echo "Test complete!"
```

Make it executable:
```bash
chmod +x test-challenge.sh
./test-challenge.sh
```

## Testing Kyverno policies

Verify your bypass prevention policies work:

```bash
# Apply policies
kubectl apply -f policies/

# Try an action that should be blocked
kubectl patch deployment data-processor -n challenge-<slug> \
  --type='json' -p='[
    {"op": "replace", "path": "/spec/template/spec/containers/0/image", "value": "nginx:latest"}
  ]'
```

Expected output:
```
Error from server: admission webhook "validate.kyverno.svc" denied the request:
resource Deployment/data-processor was blocked due to the following policies

protect-challenge-image:
  preserve-image: 'Cannot change the application image'
```

**View active policies:**
```bash
kubectl get clusterpolicy
kubectl describe clusterpolicy <policy-name>
```

## Testing edge cases

### Multiple pods

If your challenge uses multiple pods, ensure all pass validation:

```bash
# Scale up
kubectl scale deployment app --replicas=3 -n challenge-<slug>

# Wait for all pods
kubectl wait --for=condition=ready pod -l app=myapp -n challenge-<slug> --timeout=120s

# Submit - should validate all pods
kubeasy challenge submit <slug>
```

### Timing issues

Test that validations handle resources that aren't ready yet:

```bash
# Start challenge
kubeasy challenge start <slug>

# Immediately submit (should fail)
kubeasy challenge submit <slug>

# Apply fix
# ...

# Wait and submit again
sleep 30
kubeasy challenge submit <slug>
```

## Reset and clean up

### Reset challenge (keep progress)

```bash
kubeasy challenge reset <slug>
```

This resets the cluster state while keeping your submission history.

### Clean up completely

```bash
kubeasy challenge clean <slug>
```

This removes all cluster resources for the challenge.

### Start fresh

If you need a completely fresh environment:

```bash
# Delete the Kind cluster
kind delete cluster --name kubeasy

# Recreate everything
kubeasy setup
```

## Debugging validation issues

### Validation fails but fix seems correct

1. **Check resource status directly:**
   ```bash
   kubectl get pod <pod-name> -n challenge-<slug> -o yaml
   ```

2. **Verify labels match:**
   ```bash
   kubectl get pods -l app=<expected-label> -n challenge-<slug>
   ```

3. **Check recent events:**
   ```bash
   kubectl get events -n challenge-<slug> --sort-by='.lastTimestamp' | tail -20
   ```

4. **Check logs for the expected string:**
   ```bash
   kubectl logs <pod-name> -n challenge-<slug> --since=5m
   ```

### Connectivity validation fails

1. **Verify service exists:**
   ```bash
   kubectl get svc -n challenge-<slug>
   ```

2. **Check endpoints:**
   ```bash
   kubectl get endpoints <service-name> -n challenge-<slug>
   ```

3. **Test from source pod:**
   ```bash
   kubectl exec -it <source-pod> -n challenge-<slug> -- curl -v http://service:port/path
   ```

4. **Check NetworkPolicies:**
   ```bash
   kubectl get networkpolicies -n challenge-<slug>
   ```

## Testing checklist

Before submitting your challenge:

- [ ] Challenge deploys with broken state
- [ ] Problem is clearly visible (errors in logs, events, or pod status)
- [ ] Kyverno policies block bypasses
- [ ] Fix resolves the issue
- [ ] All validations pass after fix
- [ ] Validation messages are helpful
- [ ] Estimated time is accurate
- [ ] Challenge works on a fresh cluster

## Next steps

- Review [Contributing Guidelines](/docs/developer/contributing) for submission requirements
- See [Validation Reference](/docs/developer/validation-reference) for validation spec details
- Check existing challenges for testing examples
